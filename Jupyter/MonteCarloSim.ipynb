{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0bae2e48",
   "metadata": {},
   "source": [
    "# Determining the Effectiveness of the High Speed Test Track testing for the determination of accelerometer error coefficients. \n",
    "### By Sean Abrahamson \n",
    "\n",
    "This is a jupyter note book walking through the code for simulating an the performace of a single accelerometer output going down the Holloman High Speed Test Track and then using a the 746 TS Reference Position Vector to computer the error coefficients using least squares. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d571973",
   "metadata": {},
   "source": [
    "### Import necessary libaries and functions from custom functions and classes from other jupiter notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc9756bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import plotly.graph_objects as go\n",
    "import pickle\n",
    "import pdb\n",
    "\n",
    "# Import other Jupyter Notebooks\n",
    "%run Thesis_Main.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1fa6b0",
   "metadata": {},
   "source": [
    "### Set initial coefficients and parameters for script\n",
    "\n",
    "Set the initial configuration parameters and logic that drives how results are computed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a20b5ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################\n",
    "#%% Initial Configuration Parameters\n",
    "############################################################\n",
    "\n",
    "# Set value for g\n",
    "\n",
    "g = 9.791807  \n",
    "\n",
    "\n",
    "# Set parameters for error added to Reference Position Vector\n",
    "\n",
    "sigmaRPV = 0.001        # Standard deviation of Random noise centered at zero added to downtrack distance (meters)\n",
    "tauRPV =  0            # Time Lag Error (seconds)\n",
    "biasRPV = 0            # Bias error in RPV (meters) \n",
    "\n",
    "# Set number of Monte Carlo Runs\n",
    "\n",
    "MCnum = 10\n",
    "\n",
    "# Set custom coefficients for Accelerometer error model. Updates accelerometer coefficient error model \n",
    "# dictionary if ChangeDefaultCoeff is set to True.\n",
    "\n",
    "CoeffDict = {'K_0': 1}\n",
    "\n",
    "# Used to determine how many coefficients to calculate.\n",
    "\n",
    "N_model_start = 0     #  0 =  K_1 (Scale Factor), 1 = K_0 (Bias), 2 = K_2, etc. \n",
    "N_model_end = 5      #  0 = K_1 (Scale Factor), 1 = K_0 (Bias), 2 = K_2, etc.\n",
    "\n",
    "\n",
    "# Clean up Model indicies and define Error Coefficient Names\n",
    "N_model = [0,0]\n",
    "# Fix indexing numbers\n",
    "N_model[0] = N_model_start  ### REVIEW THIS\n",
    "N_model[1]= N_model_end + 1\n",
    "\n",
    "# Definition of corresponding coefficient names that will be computed based on above pararmeters\n",
    "ModelList = ['K_1', 'K_0', 'K_2', 'K_3','K_4','K_5']\n",
    "\n",
    "\n",
    "############################################################\n",
    "#%% Initial Configuration Logic\n",
    "############################################################\n",
    "\n",
    "# If set to True, accelerometer model error will be updated with CoeffDict values set in intial parameters.\n",
    "\n",
    "changeDefaultCoeff = False\n",
    "\n",
    "\n",
    "# Generate New Trajectory. If set to True new Trajectory will be created and saved to .pkl file from EGI data.\n",
    "\n",
    "generateNewTrajectory = False\n",
    "\n",
    "\n",
    "# Generate New RPV. If set to True a new RPV will be generated and saved to .pkl file. If set to False, code will \n",
    "# to make sure and RPV with the parameters set in the intial configuration is available. If not availble a new RPV \n",
    "# be generated. \n",
    "generateNewRPV = True\n",
    "\n",
    "\n",
    "# LeastSquaresMethod sets the method used for Least Squares Regression analaysis. Default is set to 'LongHand'\n",
    "#  - 'LongHand':  Computes the least squares using numpy matrix multiplication. This is the only method that works for \n",
    "#                 Weighted Least Squares with correleated off diagonal values in the weighting matrix.\n",
    "#  - 'Numpy':     Uses the least squares function from the numpy.linalg library. This method should not be used if using any sort of weighted least squares method.\n",
    "#  - 'SciKit':    Computes the least squares regression using the SciKit library. This does not use any correlated off diagonal values. \n",
    "\n",
    "LeastSquaresMethod = 'LongHand'\n",
    "\n",
    "# If set to True the least squares regression method for determining error coefficients will use a \n",
    "# Weighted Least Squares Method.\n",
    "\n",
    "WLS = True\n",
    "\n",
    "# If set to true the model will perform regression analysis for each term indiviually as well as the full model as defined above or look at each individual coefficient.\n",
    "\n",
    "individualCoeffAnalysis = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5998c2f4",
   "metadata": {},
   "source": [
    "## Run Monte Carlo Simulations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46391d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/var/folders/q1/b08x7v8d7vdfddvg49_v4hq00000gn/T/ipykernel_37951/4293339431.py\u001b[0m(137)\u001b[0;36mRegressionAnalysis\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    135 \u001b[0;31m    \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    136 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 137 \u001b[0;31m    \u001b[0mprint_List\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoeff_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    138 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    139 \u001b[0;31m    \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> plotSimple(np.diag(w))\n",
      "ipdb> plotSimple(np.log(np.diag(w))\n",
      "*** SyntaxError: '(' was never closed\n",
      "ipdb> plotSimple(np.log(np.diag(w)))\n"
     ]
    }
   ],
   "source": [
    "# Intialize Data Storage variables\n",
    "coefficientEstimates = [];\n",
    "\n",
    "# Run Monte Carlo Sims\n",
    "for mc in range(MCnum):\n",
    "\n",
    "    print(f'Running MC {mc}...', end=\"\\r\")  \n",
    "    \n",
    "    ########################t######################################################################################\n",
    "    #%% Generate or import trajectory\n",
    "    if generateNewTrajectory == True:      \n",
    "        generateReferenceTrajectory()\n",
    "\n",
    "    # Import Reference Trajectory\n",
    "    referenceTrajectory = pd.read_pickle(\"./referenceTrajectory.pkl\")\n",
    "\n",
    "\n",
    "    ##############################################################################################################\n",
    "    #%% Generate track reference position vectory\n",
    "\n",
    "    # If generateNewRPV is set to False, check if an RPV exists with the specified parameters. If it does not\n",
    "    # then set generateNewRPV to True so tha generateNewRPV runs anyways.\n",
    "    if generateNewRPV == False:   \n",
    "        generateNewRPV = not os.path.isfile(f\"./RPVs/trackRPV_sig{sigmaRPV}_tau{tauRPV}_bias{biasRPV}.pkl\")\n",
    "\n",
    "    if generateNewRPV == True:    \n",
    "        generateTrackRPV(referenceTrajectory, sigmaRPV, tauRPV, biasRPV)\n",
    "\n",
    "    # Import trackRPV pickle file that matches configuration parameters\n",
    "    trackRPV = pd.read_pickle(f\"./RPVs/trackRPV_sig{sigmaRPV}_tau{tauRPV}_bias{biasRPV}.pkl\")\n",
    "\n",
    "\n",
    "    ##############################################################################################################\n",
    "    #%% Generate Simulated Accelerometer for full model\n",
    "    sensorSim, AccelObj = AccelSim(referenceTrajectory, N_model, changeDefaultCoeff, CoeffDict, g)\n",
    "    \n",
    "    \n",
    "    #%% Perform Regression Analysis for full model\n",
    "    if mc == 0:\n",
    "        coefficientDF, Error, cov_A, A, Ve_x, W, LeastSquaresMethod = RegressionAnalysis(referenceTrajectory, trackRPV, AccelObj, sensorSim, N_model, g, sigmaRPV, WLSoption = WLS, computeCovariance = True)\n",
    "        coefficientCovariance = cov_A\n",
    "    else:\n",
    "        coefficientDF, Error, cov_A, A, Ve_x, W, LeastSquaresMethod = RegressionAnalysis(referenceTrajectory, trackRPV, AccelObj, sensorSim, N_model, g, sigmaRPV, WLSoption = WLS, computeCovariance = False)\n",
    "  \n",
    "    coefficientEstimates.append(coefficientDF)\n",
    "    \n",
    "print('Completed MC runs')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfce8d29",
   "metadata": {},
   "source": [
    "# Monte Carlo Results Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3890e513",
   "metadata": {},
   "outputs": [],
   "source": [
    "CoefficientEstimateErrors = pd.DataFrame()\n",
    "\n",
    "K_1_Errors = []\n",
    "K_0_Errors = []\n",
    "K_2_Errors = []\n",
    "K_3_Errors = []\n",
    "K_4_Errors = []\n",
    "K_5_Errors = []\n",
    "\n",
    "for n in range(len(coefficientEstimates)):\n",
    "    K_1_Errors.append(coefficientEstimates[n]['Coefficient Estimate Error']['K_1'])\n",
    "    K_0_Errors.append(coefficientEstimates[n]['Coefficient Estimate Error']['K_0'])\n",
    "    K_2_Errors.append(coefficientEstimates[n]['Coefficient Estimate Error']['K_2'])\n",
    "    K_3_Errors.append(coefficientEstimates[n]['Coefficient Estimate Error']['K_3'])\n",
    "    K_4_Errors.append(coefficientEstimates[n]['Coefficient Estimate Error']['K_4'])\n",
    "    K_5_Errors.append(coefficientEstimates[n]['Coefficient Estimate Error']['K_5'])\n",
    "    \n",
    "CoefficientEstimateErrors['K_1_Errors'] = K_1_Errors\n",
    "CoefficientEstimateErrors['K_0_Errors'] = K_0_Errors\n",
    "CoefficientEstimateErrors['K_2_Errors'] = K_2_Errors\n",
    "CoefficientEstimateErrors['K_3_Errors'] = K_3_Errors\n",
    "CoefficientEstimateErrors['K_4_Errors'] = K_4_Errors\n",
    "CoefficientEstimateErrors['K_5_Errors'] = K_5_Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888103a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('K_1 Variance:', CoefficientEstimateErrors['K_1_Errors'].std()**2)\n",
    "print('K_0 Variance:', CoefficientEstimateErrors['K_0_Errors'].std()**2)\n",
    "print('K_2 Variance:', CoefficientEstimateErrors['K_2_Errors'].std()**2)\n",
    "print('K_3 Variance:', CoefficientEstimateErrors['K_3_Errors'].std()**2)\n",
    "print('K_4 Variance:', CoefficientEstimateErrors['K_4_Errors'].std()**2)\n",
    "print('K_5 Variance:', CoefficientEstimateErrors['K_5_Errors'].std()**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e89699b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.diag(coefficientCovariance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ba2dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('K_1 Mean:', CoefficientEstimateErrors['K_1_Errors'].mean())\n",
    "print('K_0 Mean:', CoefficientEstimateErrors['K_0_Errors'].mean())\n",
    "print('K_2 Mean:', CoefficientEstimateErrors['K_2_Errors'].mean())\n",
    "print('K_3 Mean:', CoefficientEstimateErrors['K_3_Errors'].mean())\n",
    "print('K_4 Mean:', CoefficientEstimateErrors['K_4_Errors'].mean())\n",
    "print('K_5 Mean:', CoefficientEstimateErrors['K_5_Errors'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138943d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(coefficientEstimates[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918a8801",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37984cc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae8074f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
